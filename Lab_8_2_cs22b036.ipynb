{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uiUq_qhdsQ0M",
        "outputId": "f75e84a0-5f9d-4f1a-b482-548211d4c279"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Life': 0, 'dessert': 1, 'eat': 2, 'first': 3, 'is': 4, 'short': 5}\n"
          ]
        }
      ],
      "source": [
        "sentence = 'Life is short, eat dessert first'\n",
        "\n",
        "dc = {s:i for i,s\n",
        "      in enumerate(sorted(sentence.replace(',', '').split()))}\n",
        "\n",
        "print(dc)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "sentence_int = torch.tensor(\n",
        "    [dc[s] for s in sentence.replace(',', '').split()]\n",
        ")\n",
        "print(sentence_int)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kk-1dbZGsfsS",
        "outputId": "7846193e-a203-4aa4-e066-445ea8a13cc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 4, 5, 2, 1, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 50_000\n",
        "\n",
        "torch.manual_seed(123)\n",
        "embed = torch.nn.Embedding(vocab_size, 3)\n",
        "embedded_sentence = embed(sentence_int).detach()\n",
        "\n",
        "print(embedded_sentence)\n",
        "print(embedded_sentence.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXPTnC0ZsiNq",
        "outputId": "78d00739-df0c-4046-9ff5-266f0712940b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.3374, -0.1778, -0.3035],\n",
            "        [ 0.1794,  1.8951,  0.4954],\n",
            "        [ 0.2692, -0.0770, -1.0205],\n",
            "        [-0.2196, -0.3792,  0.7671],\n",
            "        [-0.5880,  0.3486,  0.6603],\n",
            "        [-1.1925,  0.6984, -1.4097]])\n",
            "torch.Size([6, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "d = embedded_sentence.shape[1]\n",
        "\n",
        "d_q, d_k, d_v = 2, 2, 4\n",
        "\n",
        "W_query = torch.nn.Parameter(torch.rand(d, d_q))\n",
        "W_key = torch.nn.Parameter(torch.rand(d, d_k))\n",
        "W_value = torch.nn.Parameter(torch.rand(d, d_v))"
      ],
      "metadata": {
        "id": "e3fludGiskcR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_2 = embedded_sentence[1]\n",
        "query_2 = x_2 @ W_query\n",
        "key_2 = x_2 @ W_key\n",
        "value_2 = x_2 @ W_value\n",
        "\n",
        "print(query_2.shape)\n",
        "print(key_2.shape)\n",
        "print(value_2.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxIIWfWlsmRp",
        "outputId": "7e41761e-72a6-4b0c-a5c1-4464c32b3e24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2])\n",
            "torch.Size([2])\n",
            "torch.Size([4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keys = embedded_sentence @ W_key\n",
        "values = embedded_sentence @ W_value\n",
        "\n",
        "print(\"keys.shape:\", keys.shape)\n",
        "print(\"values.shape:\", values.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTLVz7puswHC",
        "outputId": "171275d3-066f-4522-c885-77dbbec84f2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "keys.shape: torch.Size([6, 2])\n",
            "values.shape: torch.Size([6, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "omega_24 = query_2.dot(keys[4])\n",
        "print(omega_24)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ig81GppJswri",
        "outputId": "8e94180e-8b1a-4561-e8cc-c1fb126c415c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.2903, grad_fn=<DotBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "omega_2 = query_2 @ keys.T\n",
        "print(omega_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4PwQeZ-s1sk",
        "outputId": "44fea8c1-2373-4749-93d2-c95ad807531e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.6004,  3.4707, -1.5023,  0.4991,  1.2903, -1.3374],\n",
            "       grad_fn=<SqueezeBackward4>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "attention_weights_2 = F.softmax(omega_2 / d_k**0.5, dim=0)\n",
        "print(attention_weights_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PphpETfVs4YS",
        "outputId": "29a84e21-f8bc-47e3-d0c6-c9c494afc371"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.0386, 0.6870, 0.0204, 0.0840, 0.1470, 0.0229],\n",
            "       grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "attention_weights_2 = F.softmax(omega_2 / d_k**0.5, dim=0)\n",
        "print(attention_weights_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zy6ccBYns6xq",
        "outputId": "b9a1377f-8d45-4ae2-e8fb-2d7932001266"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.0386, 0.6870, 0.0204, 0.0840, 0.1470, 0.0229],\n",
            "       grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class SelfAttention(nn.Module):\n",
        "\n",
        "    def __init__(self, d_in, d_out_kq, d_out_v):\n",
        "        super().__init__()\n",
        "        self.d_out_kq = d_out_kq\n",
        "        self.W_query = nn.Parameter(torch.rand(d_in, d_out_kq))\n",
        "        self.W_key   = nn.Parameter(torch.rand(d_in, d_out_kq))\n",
        "        self.W_value = nn.Parameter(torch.rand(d_in, d_out_v))\n",
        "\n",
        "    def forward(self, x):\n",
        "        keys = x @ self.W_key\n",
        "        queries = x @ self.W_query\n",
        "        values = x @ self.W_value\n",
        "\n",
        "        attn_scores = queries @ keys.T  # unnormalized attention weights\n",
        "        attn_weights = torch.softmax(\n",
        "            attn_scores / self.d_out_kq**0.5, dim=-1\n",
        "        )\n",
        "\n",
        "        context_vec = attn_weights @ values\n",
        "        return context_vec\n",
        "\n"
      ],
      "metadata": {
        "id": "ykhvnNqFs-eq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "# reduce d_out_v from 4 to 1, because we have 4 heads\n",
        "d_in, d_out_kq, d_out_v = 3, 2, 4\n",
        "\n",
        "sa = SelfAttention(d_in, d_out_kq, d_out_v)\n",
        "print(sa(embedded_sentence))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AXEj7lUttCQD",
        "outputId": "2c83d51d-e50e-43d0-ab74-720738e28e97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.1564,  0.1028, -0.0763, -0.0764],\n",
            "        [ 0.5313,  1.3607,  0.7891,  1.3110],\n",
            "        [-0.3542, -0.1234, -0.2626, -0.3706],\n",
            "        [ 0.0071,  0.3345,  0.0969,  0.1998],\n",
            "        [ 0.1008,  0.4780,  0.2021,  0.3674],\n",
            "        [-0.5296, -0.2799, -0.4107, -0.6006]], grad_fn=<MmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttentionWrapper(nn.Module):\n",
        "\n",
        "    def __init__(self, d_in, d_out_kq, d_out_v, num_heads):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList(\n",
        "            [SelfAttention(d_in, d_out_kq, d_out_v)\n",
        "             for _ in range(num_heads)]\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return torch.cat([head(x) for head in self.heads], dim=-1)"
      ],
      "metadata": {
        "id": "bfLD1lcMtHyE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "d_in, d_out_kq, d_out_v = 3, 2, 1\n",
        "\n",
        "sa = SelfAttention(d_in, d_out_kq, d_out_v)\n",
        "print(sa(embedded_sentence))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xyPdxOl8tLK7",
        "outputId": "268cf1fd-9b86-4816-d77d-e5444ec33636"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.0185],\n",
            "        [ 0.4003],\n",
            "        [-0.1103],\n",
            "        [ 0.0668],\n",
            "        [ 0.1180],\n",
            "        [-0.1827]], grad_fn=<MmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "block_size = embedded_sentence.shape[1]\n",
        "mha = MultiHeadAttentionWrapper(\n",
        "    d_in, d_out_kq, d_out_v, num_heads=4\n",
        ")\n",
        "\n",
        "context_vecs = mha(embedded_sentence)\n",
        "\n",
        "print(context_vecs)\n",
        "print(\"context_vecs.shape:\", context_vecs.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CctRPWpctOb7",
        "outputId": "d937a043-f1ae-4fe8-f733-3a8d82e7b31b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.0185,  0.0170,  0.1999, -0.0860],\n",
            "        [ 0.4003,  1.7137,  1.3981,  1.0497],\n",
            "        [-0.1103, -0.1609,  0.0079, -0.2416],\n",
            "        [ 0.0668,  0.3534,  0.2322,  0.1008],\n",
            "        [ 0.1180,  0.6949,  0.3157,  0.2807],\n",
            "        [-0.1827, -0.2060, -0.2393, -0.3167]], grad_fn=<CatBackward0>)\n",
            "context_vecs.shape: torch.Size([6, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CrossAttention(nn.Module):\n",
        "\n",
        "    def __init__(self, d_in, d_out_kq, d_out_v):\n",
        "        super().__init__()\n",
        "        self.d_out_kq = d_out_kq\n",
        "        self.W_query = nn.Parameter(torch.rand(d_in, d_out_kq))\n",
        "        self.W_key   = nn.Parameter(torch.rand(d_in, d_out_kq))\n",
        "        self.W_value = nn.Parameter(torch.rand(d_in, d_out_v))\n",
        "\n",
        "    def forward(self, x_1, x_2):           # x_2 is new\n",
        "        queries_1 = x_1 @ self.W_query\n",
        "\n",
        "        keys_2 = x_2 @ self.W_key          # new\n",
        "        values_2 = x_2 @ self.W_value      # new\n",
        "\n",
        "        attn_scores = queries_1 @ keys_2.T # new\n",
        "        attn_weights = torch.softmax(\n",
        "            attn_scores / self.d_out_kq**0.5, dim=-1)\n",
        "\n",
        "        context_vec = attn_weights @ values_2\n",
        "        return context_vec"
      ],
      "metadata": {
        "id": "i2Um5S7ktTFT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "d_in, d_out_kq, d_out_v = 3, 2, 4\n",
        "\n",
        "crossattn = CrossAttention(d_in, d_out_kq, d_out_v)\n",
        "\n",
        "first_input = embedded_sentence\n",
        "second_input = torch.rand(8, d_in)\n",
        "\n",
        "print(\"First input shape:\", first_input.shape)\n",
        "print(\"Second input shape:\", second_input.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TcEhgE0RtdVC",
        "outputId": "d94d9198-4531-4408-afed-99a93e97b4ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First input shape: torch.Size([6, 3])\n",
            "Second input shape: torch.Size([8, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context_vectors = crossattn(first_input, second_input)\n",
        "\n",
        "print(context_vectors)\n",
        "print(\"Output shape:\", context_vectors.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NlmRONDNthfz",
        "outputId": "6df1810d-7eb6-4d20-8316-e6da781241e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.4231, 0.8665, 0.6503, 1.0042],\n",
            "        [0.4874, 0.9718, 0.7359, 1.1353],\n",
            "        [0.4054, 0.8359, 0.6258, 0.9667],\n",
            "        [0.4357, 0.8886, 0.6678, 1.0311],\n",
            "        [0.4429, 0.9006, 0.6775, 1.0460],\n",
            "        [0.3860, 0.8021, 0.5985, 0.9250]], grad_fn=<MmBackward0>)\n",
            "Output shape: torch.Size([6, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "d_in, d_out_kq, d_out_v = 3, 2, 4\n",
        "\n",
        "W_query = nn.Parameter(torch.rand(d_in, d_out_kq))\n",
        "W_key   = nn.Parameter(torch.rand(d_in, d_out_kq))\n",
        "W_value = nn.Parameter(torch.rand(d_in, d_out_v))\n",
        "\n",
        "x = embedded_sentence\n",
        "\n",
        "keys = x @ W_key\n",
        "queries = x @ W_query\n",
        "values = x @ W_value\n",
        "\n",
        "# attn_scores are the \"omegas\",\n",
        "# the unnormalized attention weights\n",
        "attn_scores = queries @ keys.T\n",
        "\n",
        "print(attn_scores)\n",
        "print(attn_scores.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQsQvKVVtlNT",
        "outputId": "8be23017-b549-4e0b-9c94-29760c2b4a99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.0613, -0.3491,  0.1443, -0.0437, -0.1303,  0.1076],\n",
            "        [-0.6004,  3.4707, -1.5023,  0.4991,  1.2903, -1.3374],\n",
            "        [ 0.2432, -1.3934,  0.5869, -0.1851, -0.5191,  0.4730],\n",
            "        [-0.0794,  0.4487, -0.1807,  0.0518,  0.1677, -0.1197],\n",
            "        [-0.1510,  0.8626, -0.3597,  0.1112,  0.3216, -0.2787],\n",
            "        [ 0.4344, -2.5037,  1.0740, -0.3509, -0.9315,  0.9265]],\n",
            "       grad_fn=<MmBackward0>)\n",
            "torch.Size([6, 6])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attn_weights = torch.softmax(attn_scores / d_out_kq**0.5, dim=1)\n",
        "print(attn_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0FrRb9BLtpbE",
        "outputId": "6d84e1e4-e5de-4625-b7a9-8574059419ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1772, 0.1326, 0.1879, 0.1645, 0.1547, 0.1831],\n",
            "        [0.0386, 0.6870, 0.0204, 0.0840, 0.1470, 0.0229],\n",
            "        [0.1965, 0.0618, 0.2506, 0.1452, 0.1146, 0.2312],\n",
            "        [0.1505, 0.2187, 0.1401, 0.1651, 0.1793, 0.1463],\n",
            "        [0.1347, 0.2758, 0.1162, 0.1621, 0.1881, 0.1231],\n",
            "        [0.1973, 0.0247, 0.3102, 0.1132, 0.0751, 0.2794]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "block_size = attn_scores.shape[0]\n",
        "mask_simple = torch.tril(torch.ones(block_size, block_size))\n",
        "print(mask_simple)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJTxM3wAtrtb",
        "outputId": "1eac1078-226d-4c71-8f74-1308d780129b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 0., 0., 0., 0.],\n",
            "        [1., 1., 0., 0., 0., 0.],\n",
            "        [1., 1., 1., 0., 0., 0.],\n",
            "        [1., 1., 1., 1., 0., 0.],\n",
            "        [1., 1., 1., 1., 1., 0.],\n",
            "        [1., 1., 1., 1., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "masked_simple = attn_weights*mask_simple\n",
        "print(masked_simple)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHbijLOfttyL",
        "outputId": "ad9e00a2-da0c-49c7-8bfe-0e907bb14d48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1772, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.0386, 0.6870, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.1965, 0.0618, 0.2506, 0.0000, 0.0000, 0.0000],\n",
            "        [0.1505, 0.2187, 0.1401, 0.1651, 0.0000, 0.0000],\n",
            "        [0.1347, 0.2758, 0.1162, 0.1621, 0.1881, 0.0000],\n",
            "        [0.1973, 0.0247, 0.3102, 0.1132, 0.0751, 0.2794]],\n",
            "       grad_fn=<MulBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "row_sums = masked_simple.sum(dim=1, keepdim=True)\n",
        "masked_simple_norm = masked_simple / row_sums\n",
        "print(masked_simple_norm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLHGeR2Ztvrs",
        "outputId": "47a15df4-6afe-437d-f410-6e85455e5e33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.0532, 0.9468, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.3862, 0.1214, 0.4924, 0.0000, 0.0000, 0.0000],\n",
            "        [0.2232, 0.3242, 0.2078, 0.2449, 0.0000, 0.0000],\n",
            "        [0.1536, 0.3145, 0.1325, 0.1849, 0.2145, 0.0000],\n",
            "        [0.1973, 0.0247, 0.3102, 0.1132, 0.0751, 0.2794]],\n",
            "       grad_fn=<DivBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mask = torch.triu(torch.ones(block_size, block_size), diagonal=1)\n",
        "masked = attn_scores.masked_fill(mask.bool(), -torch.inf)\n",
        "print(masked)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Kok_mP3ty6b",
        "outputId": "7cb356c1-9a6a-429b-ba79-86d4e2ce44eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.0613,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
            "        [-0.6004,  3.4707,    -inf,    -inf,    -inf,    -inf],\n",
            "        [ 0.2432, -1.3934,  0.5869,    -inf,    -inf,    -inf],\n",
            "        [-0.0794,  0.4487, -0.1807,  0.0518,    -inf,    -inf],\n",
            "        [-0.1510,  0.8626, -0.3597,  0.1112,  0.3216,    -inf],\n",
            "        [ 0.4344, -2.5037,  1.0740, -0.3509, -0.9315,  0.9265]],\n",
            "       grad_fn=<MaskedFillBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attn_weights = torch.softmax(masked / d_out_kq**0.5, dim=1)\n",
        "print(attn_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tzJHh3Fzt1DE",
        "outputId": "e6809341-1fe6-4aa7-ed3a-15fb19b7e090"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.0532, 0.9468, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.3862, 0.1214, 0.4924, 0.0000, 0.0000, 0.0000],\n",
            "        [0.2232, 0.3242, 0.2078, 0.2449, 0.0000, 0.0000],\n",
            "        [0.1536, 0.3145, 0.1325, 0.1849, 0.2145, 0.0000],\n",
            "        [0.1973, 0.0247, 0.3102, 0.1132, 0.0751, 0.2794]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ]
    }
  ]
}