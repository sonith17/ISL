{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lYHl_hazzUbA"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.datasets import load_digits"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X,y = load_digits(return_X_y=True)\n",
        "X=X.flatten().reshape(-1,64)\n",
        "X,y,X.shape,y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7tr9dvz7cDy",
        "outputId": "0b0e95ca-8852-4705-b8ec-0223f07eeedb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],\n",
              "        [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n",
              "        [ 0.,  0.,  0., ..., 16.,  9.,  0.],\n",
              "        ...,\n",
              "        [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
              "        [ 0.,  0.,  2., ..., 12.,  0.,  0.],\n",
              "        [ 0.,  0., 10., ..., 12.,  1.,  0.]]),\n",
              " array([0, 1, 2, ..., 8, 9, 8]),\n",
              " (1797, 64),\n",
              " (1797,))"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s = StandardScaler()\n",
        "X = s.fit_transform(X)\n",
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSzgzVjJ73wg",
        "outputId": "998b7518-cf86-4ec0-907d-2d745bd61038"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.        , -0.33501649, -0.04308102, ..., -1.14664746,\n",
              "        -0.5056698 , -0.19600752],\n",
              "       [ 0.        , -0.33501649, -1.09493684, ...,  0.54856067,\n",
              "        -0.5056698 , -0.19600752],\n",
              "       [ 0.        , -0.33501649, -1.09493684, ...,  1.56568555,\n",
              "         1.6951369 , -0.19600752],\n",
              "       ...,\n",
              "       [ 0.        , -0.33501649, -0.88456568, ..., -0.12952258,\n",
              "        -0.5056698 , -0.19600752],\n",
              "       [ 0.        , -0.33501649, -0.67419451, ...,  0.8876023 ,\n",
              "        -0.5056698 , -0.19600752],\n",
              "       [ 0.        , -0.33501649,  1.00877481, ...,  0.8876023 ,\n",
              "        -0.26113572, -0.19600752]])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)"
      ],
      "metadata": {
        "id": "cgVjj98M8DjC"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = torch.tensor(X_train,dtype=torch.float)\n",
        "X_test = torch.tensor(X_test,dtype=torch.float)\n",
        "y_train = torch.tensor(y_train,dtype=torch.long)\n",
        "y_test = torch.tensor(y_test,dtype=torch.long)"
      ],
      "metadata": {
        "id": "SuzduBHR8Su2"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim = 64\n",
        "hidden_dim = 16\n",
        "output_dim = 10"
      ],
      "metadata": {
        "id": "-cc7NAna9NuF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w1 = torch.randn(input_dim,hidden_dim,dtype=torch.float32,requires_grad=True)\n",
        "b1 = torch.zeros(hidden_dim,dtype=torch.float32,requires_grad=True)\n",
        "w2 = torch.randn(hidden_dim,output_dim,dtype=torch.float32,requires_grad=True)\n",
        "b2 = torch.zeros(output_dim,dtype=torch.float32,requires_grad=True)\n",
        "\n",
        "w1,b1,w2,b2,w1.shape,b1.shape,w2.shape,b2.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKxPFrw29kYr",
        "outputId": "76f8a453-a93d-453f-faa6-4d5f9e1e9cee"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 0.4224, -0.3956, -0.3988,  ...,  0.3260, -0.5974,  0.8860],\n",
              "         [ 0.8344,  1.6975, -0.6181,  ...,  1.5176, -1.3268,  0.2486],\n",
              "         [ 0.0746,  0.2255,  0.3638,  ...,  1.2983, -1.7839, -0.0786],\n",
              "         ...,\n",
              "         [-1.0719, -0.4248, -0.2197,  ..., -0.6485,  0.6386,  0.0296],\n",
              "         [-0.5586, -0.0814, -0.7857,  ..., -0.3541,  0.8976,  0.7863],\n",
              "         [ 1.8987,  0.0705, -0.1088,  ...,  1.7369, -0.4838,  1.7236]],\n",
              "        requires_grad=True),\n",
              " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        requires_grad=True),\n",
              " tensor([[ 7.7723e-01, -1.7590e-01,  5.1182e-02, -2.8055e-01, -3.6533e-01,\n",
              "          -1.1593e+00,  5.9089e-01,  7.3143e-01,  4.2362e-01, -5.8089e-01],\n",
              "         [-1.0640e-01, -3.7338e-01,  2.6820e+00, -5.7596e-02,  2.1285e+00,\n",
              "          -6.3923e-01,  1.5468e-01, -1.1450e+00, -3.0831e-01,  9.2964e-01],\n",
              "         [ 1.1661e-01, -4.5583e-01,  4.1474e-01, -8.2137e-01,  1.2185e+00,\n",
              "          -2.1218e+00,  2.5652e-01, -2.5174e+00,  8.9877e-01,  7.3771e-01],\n",
              "         [ 1.5781e-01,  4.5502e-01,  2.3834e+00, -3.0563e-02,  2.1143e-01,\n",
              "           1.4116e-01,  1.3791e-01, -6.6732e-01, -1.2349e+00, -8.0690e-01],\n",
              "         [ 3.8395e-01, -4.3683e-02, -1.6454e+00, -8.7475e-02,  9.0768e-01,\n",
              "          -2.9279e-01,  1.4192e+00,  4.0880e-01, -6.3456e-01, -9.5325e-01],\n",
              "         [-1.3670e+00, -8.0916e-01,  1.5850e+00,  9.7447e-01,  2.1164e+00,\n",
              "           1.3534e+00,  7.6043e-01,  1.5542e+00, -4.1571e-01, -1.1050e+00],\n",
              "         [ 1.0721e+00,  6.6457e-01,  2.0166e-01,  1.2665e+00,  1.5063e+00,\n",
              "           9.5412e-01,  1.7125e-01,  8.5499e-01,  4.8880e-01, -2.6190e+00],\n",
              "         [-6.0186e-01, -1.7280e+00, -1.9663e+00,  8.4120e-01, -9.1458e-01,\n",
              "          -3.8947e-01,  9.6694e-01,  3.0976e-01,  1.9713e-01,  3.3550e-01],\n",
              "         [ 7.9566e-01,  8.7960e-01, -4.3283e-01, -3.7304e-01,  3.2330e-01,\n",
              "          -5.6459e-01, -8.0690e-01,  1.1168e+00,  1.6494e-01, -1.6197e+00],\n",
              "         [ 6.1253e-01, -1.0915e+00, -8.1108e-01, -2.7306e-03,  4.6784e-01,\n",
              "           7.0726e-01, -1.1188e+00,  1.2344e-01, -1.5247e+00,  1.0519e+00],\n",
              "         [ 9.0846e-01,  1.0031e+00,  1.3838e+00, -2.4405e+00, -1.1810e+00,\n",
              "          -2.7942e-01,  4.5732e-01, -4.8133e-01,  3.7340e-01,  7.0625e-02],\n",
              "         [-1.2248e-01,  9.5756e-01,  5.6893e-01, -1.7848e-02, -7.7342e-01,\n",
              "           6.4624e-01, -7.0131e-01, -7.1891e-01,  1.2965e-01, -2.8589e+00],\n",
              "         [-4.4072e-01,  6.4254e-02,  1.3463e+00, -1.6951e+00, -8.9715e-01,\n",
              "          -7.4847e-01,  9.6465e-01,  3.2142e-01,  1.8286e+00, -1.3516e-01],\n",
              "         [-2.9631e+00,  5.4829e-01, -2.4159e-02,  7.7934e-01,  8.3208e-01,\n",
              "           5.4325e-01,  8.0174e-01, -9.0274e-01,  3.7572e-01,  1.2631e+00],\n",
              "         [-1.4916e-02,  8.0212e-01, -5.4010e-02,  1.1453e+00,  6.6020e-01,\n",
              "           1.7301e+00, -3.6242e-01,  1.1013e+00,  9.3802e-01,  1.5335e+00],\n",
              "         [ 1.5531e+00,  1.2150e+00, -1.3158e+00,  5.0229e-01,  3.8787e-01,\n",
              "          -4.5024e-01, -8.4840e-01, -5.6876e-01,  2.1578e+00,  5.8891e-01]],\n",
              "        requires_grad=True),\n",
              " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True),\n",
              " torch.Size([64, 16]),\n",
              " torch.Size([16]),\n",
              " torch.Size([16, 10]),\n",
              " torch.Size([10]))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def relu(x):\n",
        "  return torch.maximum(x,torch.zeros_like(x))\n",
        "\n",
        "def softmax(x):\n",
        "  ex = torch.exp(x-torch.max(x,dim=1,keepdim=True)[0])\n",
        "  return ex/ex.sum(dim=1,keepdim=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "OtXYVdwO-gJG"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward(x):\n",
        "  z1 = torch.matmul(x,w1)+b1\n",
        "  a1 = relu(z1)\n",
        "  z2 = torch.matmul(a1,w2)+b2\n",
        "  a2 = softmax(z2)\n",
        "  return a2\n",
        "\n",
        "def predict(x):\n",
        "  with torch.no_grad():\n",
        "    y_pred = forward(x)\n",
        "    _,prediction=torch.max(y_pred,dim=1)\n",
        "  return prediction"
      ],
      "metadata": {
        "id": "hs19vN1y_NmR"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def CE_loss(y_pred,y_true):\n",
        "  y_one_hot = torch.zeros_like(y_pred)\n",
        "  y_one_hot[torch.arange(y_pred.shape[0]),y_true] = 1\n",
        "  return -torch.mean(torch.sum(y_one_hot*torch.log(y_pred+1e-2),dim=1))"
      ],
      "metadata": {
        "id": "tu9E3QqOAj3O"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 1e-2\n",
        "epochs = 100\n",
        "for epoch in range(epochs):\n",
        "  y_pred = forward(X_train)\n",
        "  loss = CE_loss(y_pred,y_train)\n",
        "  loss.backward()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    w1 -= lr*w1.grad\n",
        "    b1 -= lr*b1.grad\n",
        "    w2 -= lr*w2.grad\n",
        "    b2 -= lr*b2.grad\n",
        "\n",
        "    w1.grad.zero_()\n",
        "    b1.grad.zero_()\n",
        "    w2.grad.zero_()\n",
        "    b2.grad.zero_()\n",
        "\n",
        "  print(f\"Epoch {epoch+1}/{epochs} Loss: {loss.item()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P55v04gsAp7V",
        "outputId": "ccb6977a-969e-46c3-90a8-0ab6c321e9f3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100 Loss: 4.044790744781494\n",
            "Epoch 2/100 Loss: 4.044158458709717\n",
            "Epoch 3/100 Loss: 4.043522357940674\n",
            "Epoch 4/100 Loss: 4.042882442474365\n",
            "Epoch 5/100 Loss: 4.042239665985107\n",
            "Epoch 6/100 Loss: 4.041592597961426\n",
            "Epoch 7/100 Loss: 4.040943145751953\n",
            "Epoch 8/100 Loss: 4.040288925170898\n",
            "Epoch 9/100 Loss: 4.039631366729736\n",
            "Epoch 10/100 Loss: 4.038969993591309\n",
            "Epoch 11/100 Loss: 4.03830623626709\n",
            "Epoch 12/100 Loss: 4.037639617919922\n",
            "Epoch 13/100 Loss: 4.036968231201172\n",
            "Epoch 14/100 Loss: 4.036293029785156\n",
            "Epoch 15/100 Loss: 4.035613059997559\n",
            "Epoch 16/100 Loss: 4.0349297523498535\n",
            "Epoch 17/100 Loss: 4.034241676330566\n",
            "Epoch 18/100 Loss: 4.033548831939697\n",
            "Epoch 19/100 Loss: 4.03285026550293\n",
            "Epoch 20/100 Loss: 4.0321478843688965\n",
            "Epoch 21/100 Loss: 4.031440258026123\n",
            "Epoch 22/100 Loss: 4.030726909637451\n",
            "Epoch 23/100 Loss: 4.030007839202881\n",
            "Epoch 24/100 Loss: 4.0292840003967285\n",
            "Epoch 25/100 Loss: 4.0285539627075195\n",
            "Epoch 26/100 Loss: 4.027818202972412\n",
            "Epoch 27/100 Loss: 4.02707576751709\n",
            "Epoch 28/100 Loss: 4.026327133178711\n",
            "Epoch 29/100 Loss: 4.025571346282959\n",
            "Epoch 30/100 Loss: 4.02480936050415\n",
            "Epoch 31/100 Loss: 4.0240397453308105\n",
            "Epoch 32/100 Loss: 4.023262977600098\n",
            "Epoch 33/100 Loss: 4.022479057312012\n",
            "Epoch 34/100 Loss: 4.021687030792236\n",
            "Epoch 35/100 Loss: 4.0208868980407715\n",
            "Epoch 36/100 Loss: 4.020078182220459\n",
            "Epoch 37/100 Loss: 4.019260406494141\n",
            "Epoch 38/100 Loss: 4.018434524536133\n",
            "Epoch 39/100 Loss: 4.017598628997803\n",
            "Epoch 40/100 Loss: 4.016753673553467\n",
            "Epoch 41/100 Loss: 4.015898704528809\n",
            "Epoch 42/100 Loss: 4.01503324508667\n",
            "Epoch 43/100 Loss: 4.014157295227051\n",
            "Epoch 44/100 Loss: 4.013270378112793\n",
            "Epoch 45/100 Loss: 4.012372016906738\n",
            "Epoch 46/100 Loss: 4.0114617347717285\n",
            "Epoch 47/100 Loss: 4.010539531707764\n",
            "Epoch 48/100 Loss: 4.009605407714844\n",
            "Epoch 49/100 Loss: 4.008658409118652\n",
            "Epoch 50/100 Loss: 4.007698059082031\n",
            "Epoch 51/100 Loss: 4.006723880767822\n",
            "Epoch 52/100 Loss: 4.0057373046875\n",
            "Epoch 53/100 Loss: 4.004737854003906\n",
            "Epoch 54/100 Loss: 4.003723621368408\n",
            "Epoch 55/100 Loss: 4.002694129943848\n",
            "Epoch 56/100 Loss: 4.001648426055908\n",
            "Epoch 57/100 Loss: 4.0005879402160645\n",
            "Epoch 58/100 Loss: 3.9995102882385254\n",
            "Epoch 59/100 Loss: 3.9984166622161865\n",
            "Epoch 60/100 Loss: 3.9973061084747314\n",
            "Epoch 61/100 Loss: 3.9961798191070557\n",
            "Epoch 62/100 Loss: 3.9950356483459473\n",
            "Epoch 63/100 Loss: 3.9938762187957764\n",
            "Epoch 64/100 Loss: 3.992701292037964\n",
            "Epoch 65/100 Loss: 3.9915099143981934\n",
            "Epoch 66/100 Loss: 3.990302324295044\n",
            "Epoch 67/100 Loss: 3.989078998565674\n",
            "Epoch 68/100 Loss: 3.987839937210083\n",
            "Epoch 69/100 Loss: 3.9865846633911133\n",
            "Epoch 70/100 Loss: 3.9853155612945557\n",
            "Epoch 71/100 Loss: 3.9840312004089355\n",
            "Epoch 72/100 Loss: 3.982732057571411\n",
            "Epoch 73/100 Loss: 3.981419563293457\n",
            "Epoch 74/100 Loss: 3.9800939559936523\n",
            "Epoch 75/100 Loss: 3.978755235671997\n",
            "Epoch 76/100 Loss: 3.9774045944213867\n",
            "Epoch 77/100 Loss: 3.9760425090789795\n",
            "Epoch 78/100 Loss: 3.9746692180633545\n",
            "Epoch 79/100 Loss: 3.9732844829559326\n",
            "Epoch 80/100 Loss: 3.9718897342681885\n",
            "Epoch 81/100 Loss: 3.970484972000122\n",
            "Epoch 82/100 Loss: 3.969071388244629\n",
            "Epoch 83/100 Loss: 3.967648983001709\n",
            "Epoch 84/100 Loss: 3.9662177562713623\n",
            "Epoch 85/100 Loss: 3.964779853820801\n",
            "Epoch 86/100 Loss: 3.963334321975708\n",
            "Epoch 87/100 Loss: 3.9618828296661377\n",
            "Epoch 88/100 Loss: 3.960425853729248\n",
            "Epoch 89/100 Loss: 3.9589638710021973\n",
            "Epoch 90/100 Loss: 3.9574995040893555\n",
            "Epoch 91/100 Loss: 3.95603084564209\n",
            "Epoch 92/100 Loss: 3.9545602798461914\n",
            "Epoch 93/100 Loss: 3.9530889987945557\n",
            "Epoch 94/100 Loss: 3.9516172409057617\n",
            "Epoch 95/100 Loss: 3.950146436691284\n",
            "Epoch 96/100 Loss: 3.9486782550811768\n",
            "Epoch 97/100 Loss: 3.9472122192382812\n",
            "Epoch 98/100 Loss: 3.9457507133483887\n",
            "Epoch 99/100 Loss: 3.9442944526672363\n",
            "Epoch 100/100 Loss: 3.9428436756134033\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = predict(X_test)\n",
        "accuracy = (y_pred==y_test).sum().item()/y_test.size(0)\n",
        "print(f\"Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DG2oNAsB9nx",
        "outputId": "92bc4f8e-c91b-49a7-8f4b-c624ed924c93"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.14722222222222223\n"
          ]
        }
      ]
    }
  ]
}