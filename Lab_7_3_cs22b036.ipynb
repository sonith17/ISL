{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6eJWm5Yv_H8u"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_size=28\n",
        "sequence_length =28\n",
        "num_layers=2\n",
        "hidden_size=256\n",
        "\n",
        "learning_rate = 0.001\n",
        "num_epochs = 5\n",
        "\n",
        "num_classes =10\n",
        "batch_size = 64"
      ],
      "metadata": {
        "id": "SHCWAcWm_uxJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleRNN(nn.Module):\n",
        "    def __init__(self, input_size, num_layers, hidden_size, sequence_length, num_classes):\n",
        "        super(SimpleRNN, self).__init__()\n",
        "        self.num_layers = num_layers\n",
        "        self.hidden_size= hidden_size\n",
        "\n",
        "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc1 = nn.Linear(hidden_size * sequence_length, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
        "\n",
        "        out, _ = self.rnn(x, h0)\n",
        "#         print(out.shape)\n",
        "        out = out.reshape(out.shape[0], -1)\n",
        "        out = self.fc1(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "HhTFHrgx_z65"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleGRU(nn.Module):\n",
        "    def __init__(self, input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, num_classes=num_classes, sequence_length=sequence_length):\n",
        "        super(SimpleGRU, self).__init__()\n",
        "        self.hidden_size  = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc1 = nn.Linear(hidden_size * sequence_length, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
        "\n",
        "        out,_ = self.gru(x, h0)\n",
        "        out = out.reshape(out.shape[0], -1)\n",
        "        out = self.fc1(out)\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "ThIvhu5U_6PA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleLSTM(nn.Module):\n",
        "    def __init__(self, input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, sequence_length=sequence_length, num_classes=num_classes):\n",
        "        super(SimpleLSTM, self).__init__()\n",
        "\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc1 = nn.Linear(hidden_size * sequence_length, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device=device)\n",
        "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device=device)\n",
        "\n",
        "        out, _ = self.lstm(x,(h0, c0))\n",
        "        out = out.reshape(out.size(0), -1)\n",
        "        out = self.fc1(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "jcETklXaAGFu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJYLOAohATkA",
        "outputId": "b36c55e0-be73-4c27-c624-5643f4f0f53a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "models = [SimpleRNN( input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, num_classes=num_classes, sequence_length=sequence_length).to(device=device),SimpleGRU().to(device=device),SimpleLSTM().to(device=device)]"
      ],
      "metadata": {
        "id": "6eKqqgu-AeB7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for model in models:\n",
        "  print(model._get_name())\n",
        "  x = torch.randn(64,28,28).to(device=device)\n",
        "  y = model(x)\n",
        "  print(y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "saBxHJgmAhDI",
        "outputId": "e23f6022-4c0c-4062-a845-cc27db1e5fd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SimpleRNN\n",
            "torch.Size([64, 10])\n",
            "SimpleGRU\n",
            "torch.Size([64, 10])\n",
            "SimpleLSTM\n",
            "torch.Size([64, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "class MnistDataset(Dataset):\n",
        "    def __init__(self, datapath):\n",
        "        super(MnistDataset).__init__()\n",
        "        df = pd.read_csv(datapath, dtype=np.float)\n",
        "\n",
        "        self.x = torch.from_numpy(df.iloc[:, 1:].values)\n",
        "        self.x = self.x.reshape(self.x.size(0), 1, 28, 28).squeeze(1) # GRU and RNN expect N * 28 * 28\n",
        "        self.x = self.x.float()\n",
        "\n",
        "        self.y = torch.from_numpy(df.iloc[:, 0].values)\n",
        "        self.y = self.y.long()\n",
        "\n",
        "        self.n_samples = df.shape[0]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.x[index], self.y[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.n_samples"
      ],
      "metadata": {
        "id": "chwZQDjeAjWY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((28, 28)),\n",
        "    transforms.ToTensor(),\n",
        "])\n"
      ],
      "metadata": {
        "id": "kErhpsK5C4xG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = datasets.MNIST(root='./', train=True, transform=transform, download=True)\n",
        "test_dataset = datasets.MNIST(root='./', train=False, transform=transform, download=True)"
      ],
      "metadata": {
        "id": "GYVU8ElEAmRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x, y = train_dataset[0]\n",
        "print(x.shape, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mylg4MAVArjW",
        "outputId": "b198be01-8903-4605-d043-d77b4ec4e4d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 28, 28]) 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_dataloader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "cjeH6G5HAvRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_criterion  = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr = learning_rate)"
      ],
      "metadata": {
        "id": "0N0M7DuKBGVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for model in models:\n",
        "  print(model._get_name())\n",
        "  current_loss = 0\n",
        "  for epoch in range(num_epochs):\n",
        "      for data, target in tqdm(train_dataloader):\n",
        "          data = data.to(device=device)\n",
        "          target = target.to(device=device)\n",
        "          data.squeeze_(1)\n",
        "          score = model(data)\n",
        "          loss = loss_criterion(score, target)\n",
        "          current_loss = loss\n",
        "\n",
        "          optimizer.zero_grad()\n",
        "          loss.backward()\n",
        "\n",
        "          optimizer.step()\n",
        "      print(f\"At epoch: {epoch}, loss: {current_loss}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VCZhObp3BKur",
        "outputId": "2279acb8-5810-40cd-9e67-7ad67a312dec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SimpleRNN\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 938/938 [00:11<00:00, 79.41it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "At epoch: 0, loss: 2.286947250366211\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 938/938 [00:08<00:00, 109.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "At epoch: 1, loss: 2.3030507564544678\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 938/938 [00:08<00:00, 114.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "At epoch: 2, loss: 2.311488151550293\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 938/938 [00:08<00:00, 112.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "At epoch: 3, loss: 2.3215227127075195\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 938/938 [00:08<00:00, 110.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "At epoch: 4, loss: 2.295093536376953\n",
            "SimpleGRU\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 938/938 [00:10<00:00, 91.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "At epoch: 0, loss: 2.295081615447998\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 938/938 [00:10<00:00, 92.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "At epoch: 1, loss: 2.2987771034240723\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 938/938 [00:09<00:00, 98.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "At epoch: 2, loss: 2.3044912815093994\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 938/938 [00:10<00:00, 91.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "At epoch: 3, loss: 2.306396007537842\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 938/938 [00:10<00:00, 85.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "At epoch: 4, loss: 2.2920422554016113\n",
            "SimpleLSTM\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 938/938 [00:10<00:00, 86.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "At epoch: 0, loss: 0.01781553402543068\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 938/938 [00:10<00:00, 86.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "At epoch: 1, loss: 0.028112657368183136\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 938/938 [00:10<00:00, 87.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "At epoch: 2, loss: 0.005351718980818987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 938/938 [00:10<00:00, 87.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "At epoch: 3, loss: 0.0028403163887560368\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 938/938 [00:10<00:00, 85.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "At epoch: 4, loss: 0.00018620127229951322\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def check_accuracy(dlr,model):\n",
        "\n",
        "    total_correct = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x, y in dlr:\n",
        "            x = x.to(device=device)\n",
        "            y = y.to(device=device)\n",
        "            x.squeeze_(1)\n",
        "            score = model(x)\n",
        "            _,predictions = score.max(1)\n",
        "\n",
        "            total_correct += (y==predictions).sum()\n",
        "            total_samples += predictions.size(0)\n",
        "\n",
        "    model.train()\n",
        "    print(f\"total samples: {total_samples} total_correct: {total_correct} accuracy : {float(total_correct/total_samples)* 100}\")"
      ],
      "metadata": {
        "id": "K0txgPB6BOMY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for model in models:\n",
        "  print(model._get_name())\n",
        "  check_accuracy(train_dataloader, model)\n",
        "  check_accuracy(test_dataloader, model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k27NsLHNBQRm",
        "outputId": "1585e2fb-5d63-4798-caef-5247fed1c64a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SimpleRNN\n",
            "total samples: 60000 total_correct: 6153 accuracy : 10.254999995231628\n",
            "total samples: 10000 total_correct: 1058 accuracy : 10.579999536275864\n",
            "SimpleGRU\n",
            "total samples: 60000 total_correct: 7308 accuracy : 12.1799997985363\n",
            "total samples: 10000 total_correct: 1159 accuracy : 11.589999496936798\n",
            "SimpleLSTM\n",
            "total samples: 60000 total_correct: 59470 accuracy : 99.11666512489319\n",
            "total samples: 10000 total_correct: 9872 accuracy : 98.71999621391296\n"
          ]
        }
      ]
    }
  ]
}